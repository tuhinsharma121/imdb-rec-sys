{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a crawler class to crawl imdb movie data. It records actors, director, writers, genres, rating, keywords, user review count, critic review count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json_to_file(data,path):\n",
    "    with open(path, 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "\n",
    "class ImdbCrawler(object):\n",
    "    \n",
    "    def __init__(self,index_url):\n",
    "        self.index_url = index_url\n",
    "        self.imdb_url = \"http://www.imdb.com\"\n",
    "        \n",
    "    def get_actors(self,movie_soup):\n",
    "        actors = movie_soup.findAll(\"div\", {\"class\": \"credit_summary_item\"})[2].getText()\n",
    "        movie_actors = actors.split(\"|\")[0].replace(\",\",\"\").split(\"\\n\\n\")[1:]\n",
    "        movie_actors = [movie_actor.replace(\"\\n\",\"\").strip() for movie_actor in movie_actors]\n",
    "        return movie_actors\n",
    "    \n",
    "    def get_director(self,movie_soup):\n",
    "        director = movie_soup.findAll(\"div\", {\"class\": \"credit_summary_item\"})[0].getText()\n",
    "        movie_director = director.split(\"\\n\")[3].strip()\n",
    "        return movie_director\n",
    "    \n",
    "    def get_writers(self,movie_soup):\n",
    "        writers = movie_soup.findAll(\"div\", {\"class\": \"credit_summary_item\"})[1].getText()\n",
    "        movie_writers = writers.split(\"|\")[0].replace(\",\",\"\").split(\"\\n\\n\")[1:]\n",
    "        movie_writers = [movie_writer.split(\"(\")[0].strip() for movie_writer in movie_writers]\n",
    "        return movie_writers\n",
    "    \n",
    "    def get_genres(self,movie_soup):\n",
    "        genres = movie_soup.findAll(\"div\", {\"class\": \"see-more inline canwrap\"})[1].getText()\n",
    "        movie_genres = genres.replace(\"\\xa0|\",\"\").strip().split('\\n')[1:]\n",
    "        movie_genres = [movie_genre.strip() for movie_genre in movie_genres]\n",
    "        return movie_genres\n",
    "    \n",
    "    def get_rating(self,movie_soup):\n",
    "        rating = movie_soup.find(\"div\", {\"class\": \"ratingValue\"}).getText() \n",
    "        movie_rating = rating.rstrip().split(\"/\")[0].strip()\n",
    "        return movie_rating\n",
    "    \n",
    "    def get_keywords(self,movie_soup):\n",
    "        keywords = movie_soup.findAll(\"div\", {\"class\": \"see-more inline canwrap\"})[0].getText()\n",
    "        movie_keywords = keywords.replace(\"Plot Keywords:\",\"\").strip().split('\\n|')[:-1]\n",
    "        movie_keywords = [movie_keyword.strip() for movie_keyword in movie_keywords]\n",
    "        return movie_keywords\n",
    "    \n",
    "    def get_user_review_count(self,movie_soup):\n",
    "        count = movie_soup.find(\"div\", {\"class\": \"hiddenImportant\"}).getText().strip()\n",
    "        user_count = count.split('\\n')[0].split(\" \")[0].replace(',',\"\")\n",
    "        return user_count\n",
    "    \n",
    "    def get_critic_review_count(self,movie_soup):\n",
    "        count = movie_soup.find(\"div\", {\"class\": \"hiddenImportant\"}).getText().strip()\n",
    "        critic_count = count.split('\\n')[1].split(\" \")[0].replace(',',\"\")\n",
    "        return critic_count\n",
    "    \n",
    "    def get_soup(self,url):\n",
    "        req = requests.get(url)\n",
    "        page = req.text\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        return soup\n",
    "    \n",
    "    def run(self,top_n=250):\n",
    "        result_array = list()\n",
    "        index_soup = self.get_soup(index_url)\n",
    "        for i in range(top_n):\n",
    "            result = dict()\n",
    "            content = str(index_soup.findAll('td', {'class':'titleColumn'})[i])\n",
    "            movie_name = str(re.findall( '>(.*?)</a>', content)[0])\n",
    "            movie_year = index_soup.findAll('span', {'class':'secondaryInfo'})[i].getText()[1:-1]\n",
    "\n",
    "            href = str(re.findall( '<a href=\"(.*?)\\?', content)[0])\n",
    "            movie_url = self.imdb_url+href\n",
    "            \n",
    "            movie_soup = self.get_soup(url=movie_url)\n",
    "\n",
    "            result['movie_name']=movie_name\n",
    "            result['movie_year']=movie_year\n",
    "            result['actors']=self.get_actors(movie_soup)\n",
    "            result['director']=self.get_director(movie_soup)\n",
    "            result['writers']=self.get_writers(movie_soup)\n",
    "            result['genres']=self.get_genres(movie_soup)\n",
    "            result['rating']=self.get_rating(movie_soup)\n",
    "            result['keywords']=self.get_keywords(movie_soup)\n",
    "            result['user_count']=self.get_user_review_count(movie_soup)\n",
    "            result['critic_count']=self.get_critic_review_count(movie_soup)\n",
    "\n",
    "            result_array.append(result)\n",
    "        \n",
    "        return result_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It takes around 12 minutes to collect the top 250 movie data. The data is stored as jsonarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time :  541.1956050395966\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    t0 = time()\n",
    "    index_url = \"http://www.imdb.com/chart/top?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=2417962742&pf_rd_r=0M85G1V8JHW928EHBETF&pf_rd_s=right-4&pf_rd_t=15506&pf_rd_i=moviemeter&ref_=chtmvm_ql_3\"\n",
    "    im = ImdbCrawler(index_url=index_url) \n",
    "    data = im.run(top_n=250)  \n",
    "    save_json_to_file(path='../rec_platform/data/imdb_data.json',data=data)\n",
    "    print('running time : ',time()-t0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
